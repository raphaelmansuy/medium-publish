<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Markdown Processed Output</title>
</head>
<body>
<h2>Iteration of Thought (IoT) Framework</h2>
<h3>1. Introduction</h3>
<p>Generating accurate and contextually relevant responses using AI is more critical than ever. Whether you're developing chatbots, virtual assistants, or any application that relies on natural language processing, understanding how to leverage frameworks like the Iteration of Thought (IoT) can significantly enhance your results.</p>
<p>This implementation is based on the article: https://arxiv.org/pdf/2409.12618</p>
<p><img alt="Image" src="https://elitizon-public.s3.us-west-2.amazonaws.com/assets//5bdfb5e28691b6a971df40f4def6b58fffcb1b1b7bf904bef972b29c560e0bf0.jpeg"/></p>
<blockquote>
<p>üí° Iteration of Thought: Leveraging Inner Dialogue for Autonomous Large Language Model Reasoning</p>
</blockquote>
<h3>Understanding the Components of Iteration of Tought (IoT)</h3>
<p>1Ô∏è‚É£  <strong>Inner Dialogue Agent (IDA)</strong>:</p>
<p>‚Ä¢ Think of the IDA as a personal tutor or guide that helps the LLM refine its responses. Just like a student who asks questions to clarify their understanding, the IDA generates context-sensitive prompts based on the original user query and the LLM's previous responses. This is akin to having a conversation where each response leads to further questions that deepen understanding.</p>
<p>‚Ä¢ Mathematically, we can represent this as a function: </p>
<pre><code> **C: Q √ó R √ó K' ‚Üí P**
 where **Q** is the set of possible queries, **R** represents potential responses from the LLM, and **P** denotes the generated prompts. Each iteration allows the IDA to dynamically adjust its guidance based on what has been previously discussed.
</code></pre>
<p>2Ô∏è‚É£  <strong>LLM Agent (LLMA)</strong>:</p>
<p>‚Ä¢ The LLMA is like the brain of the operation, processing the prompts generated by the IDA. It uses its internal knowledge base to refine its responses further. Imagine it as a researcher who takes feedback from their mentor (the IDA) and uses that feedback to improve their work.</p>
<p>‚Ä¢ This relationship can be expressed mathematically as:</p>
<pre><code> **L: Q √ó P √ó K ‚Üí R**
 Here, **L** takes in a query **q**, a prompt **p**, and a knowledge base **K**, producing a refined response **r**.
</code></pre>
<p>3Ô∏è‚É£  <strong>Iterative Prompting Loop</strong>:</p>
<p>‚Ä¢ The iterative loop is where the magic happens. It involves back-and-forth communication between the IDA and LLMA. Each time the LLMA generates a response, it is evaluated by the IDA, which then creates a new prompt for further refinement. This process continues until either a satisfactory answer is reached or a maximum number of iterations is completed.</p>
<p>‚Ä¢ This loop can be visualized as a conversation where each participant builds on what the other has said, leading to deeper insights and improved answers.</p>
<h4>Why Use IoT?</h4>
<p>The IoT framework is particularly effective in situations where complex queries require nuanced understanding or where initial responses may lack depth or clarity. It allows for adaptive exploration across different reasoning paths without discarding potentially valuable insights‚Äîunlike traditional methods that may generate multiple reasoning paths but ultimately discard most of them.</p>
<h4>When to use it?</h4>
<p>The IoT framework is particularly useful in scenarios where complex queries require nuanced understanding or where initial responses may lack depth or clarity. It's ideal for applications in education, customer support, content generation, and more.</p>
<h3>2. Getting Started</h3>
<h4>Setting Up Your Environment</h4>
<p>To get started with the IoT framework, you'll need to set up your environment correctly:</p>
<p>1Ô∏è‚É£  <strong>Install Python:</strong> Ensure you have Python installed on your machine (version 3.11 or higher).</p>
<p>2Ô∏è‚É£  <strong>Set up OpenAI API:</strong> Obtain your API key from OpenAI and set it as an environment variable. (You can use another model for example ollama/gemma2:2b)</p>
<p>3Ô∏è‚É£  <strong>Install Poetry:</strong> If you haven't already, install Poetry by following the instructions on the <a href="https://python-poetry.org/docs/#installation">Poetry website</a>.</p>
<p>4Ô∏è‚É£  <strong>Clone the Repository:</strong> Clone the repository containing the IoT framework code:</p>
<pre><code>git clone https://github.com/raphaelmansuy/iteration_of_thought
cd iteration_of_thought
</code></pre>
<p>5Ô∏è‚É£  <strong>Install Dependencies:</strong> Use Poetry to install required packages:</p>
<pre><code>poetry install
</code></pre>
<h4>Running the Program</h4>
<p>To run the program, you can use the following command within the Poetry environment:</p>
<p>1Ô∏è‚É£  <strong>Activate the Poetry Shell:</strong></p>
<pre><code>poetry shell
</code></pre>
<p>2Ô∏è‚É£  <strong>Run the Main Script:</strong></p>
<pre><code>python src/iot_agent/main.py --method AIoT --query "Your query here" --temperature 0.5
</code></pre>
<p>You can specify the method (<code>AIoT</code> or <code>GIoT</code>), the query, and the sampling temperature for the LLM response.</p>
<h4>Understanding the Code Structure</h4>
<p>The provided code consists of several key components:</p>
<p>‚Ä¢ <strong>IterationOfThought Class:</strong> This class manages the iteration process using specified models and includes methods for both AIoT and GIoT.</p>
<p>‚Ä¢ <strong>Methods:</strong> </p>
<p>‚Ä¢ <code>_call_llm</code>: Handles API calls to an LLLM service.</p>
<p>‚Ä¢ <code>inner_dialogue_agent</code>: Generates new prompts based on previous responses to refine the output.</p>
<p>‚Ä¢ <code>llm_agent</code>: Combines the user query with the generated prompt to produce a refined response.</p>
<p>‚Ä¢ <code>stopping_criterion</code>: Determines when to stop iterating based on the content of the response.</p>
<p>‚Ä¢ <code>aiot</code>: Implements the Autonomous Iteration of Thought process.</p>
<p>‚Ä¢ <code>giot</code>: Implements the Guided Iteration of Thought process.</p>
<h3>3. Code Explanation</h3>
<h4>Main Components</h4>
<p>1Ô∏è‚É£  <strong>Imports and Configuration:</strong></p>
<p>The code begins by importing necessary libraries and setting up configuration variables, including the OpenAI API key and model type.</p>
<pre><code>import os
import time
import signal
from typing import Optional
from loguru import logger
import click
from rich.console import Console
from rich.panel import Panel
from rich.progress import Progress, SpinnerColumn, TextColumn
from rich.prompt import Prompt
from rich.table import Table
from rich.markdown import Markdown
from litellm import completion
import requests  # Added for handling URL requests
</code></pre>
<p>2Ô∏è‚É£  <strong>API Key Handling:</strong></p>
<p>The API key is retrieved from the environment variables. If it is not set, an error is raised.</p>
<pre><code>API_KEY = os.getenv("OPENAI_API_KEY")
if not API_KEY:
    raise ValueError("OpenAI API key must be set as an environment variable.")
</code></pre>
<p>3Ô∏è‚É£  <strong>IterationOfThought Class:</strong></p>
<p>This class encapsulates the logic for both AIoT and GIoT methods. It initializes with parameters such as the model type, maximum iterations, timeout settings, and temperature.</p>
<pre><code>class IterationOfThought:
    def __init__(self, model: str = MODEL, max_iterations: int = 5, timeout: int = 30, temperature: float = 0.5):
        self.model = model
        self.max_iterations = max_iterations
        self.timeout = timeout
        self.temperature = temperature
</code></pre>
<p>4Ô∏è‚É£  <strong>API Call Method:</strong></p>
<p>The <code>_call_llm</code> method handles the interaction with the OpenAI API, including error handling for rate limits.</p>
<pre><code>def _call_llm(self, prompt: str, temperature: Optional[float] = None, max_retries: int = 3) -&gt; str:
    for _ in range(max_retries):
        try:
            with console.status(f"[bold green]Calling {self.model} API...", spinner="dots"):
                response = completion(
                    model=self.model,
                    temperature=temperature or self.temperature,
                    messages=[{"role": "user", "content": prompt}],
                )
            return response["choices"][0]["message"]["content"].strip()
        except Exception as e:
            console.print(f"[red]Error: {e}")
            return ""
    console.print("[red]Failed to get a response from OpenAI API after max retries")
    return ""
</code></pre>
<p>5Ô∏è‚É£  <strong>Inner Dialogue Agent:</strong></p>
<p>This method generates a new prompt based on the previous response, encouraging deeper reasoning.</p>
<pre><code>def inner_dialogue_agent(self, query: str, previous_response: str) -&gt; str:
    prompt = (
        f"Given the original query: '{query}' and the previous response: '{previous_response}', "
        "generate an instructive and context-specific prompt to refine and improve the answer."
    )
    return self._call_llm(prompt)
</code></pre>
<p>6Ô∏è‚É£  <strong>AIoT and GIoT Methods:</strong></p>
<p>The <code>aiot</code> method implements the autonomous iteration process, while the <code>giot</code> method follows a fixed number of iterations.</p>
<pre><code>def aiot(self, query: str) -&gt; str:
    # Implementation of AIoT
</code></pre>
<pre><code>def giot(self, query: str, fixed_iterations: int) -&gt; str:
    # Implementation of GIoT
</code></pre>
<p>7Ô∏è‚É£  <strong>User Interaction:</strong></p>
<p>The <code>get_user_query</code> function prompts the user for input, allowing for a sample query or a custom one.</p>
<pre><code>def get_user_query() -&gt; str:
    user_input = Prompt.ask("Query", default=sample_query)
    return user_input
</code></pre>
<p>8Ô∏è‚É£  <strong>Main Function:</strong></p>
<p>The <code>main</code> function orchestrates the execution of the program, handling user input and displaying results.</p>
<pre><code>@click.command()
@click.option("--method", type=click.Choice(["AIoT", "GIoT", "both"]), default="AIoT", help="Choose the method to run")
def main(method: str) -&gt; None:
    # Main execution logic
</code></pre>
<h3>4. Examples of IoT in Action</h3>
<h4>Simple Example: Basic Query Handling</h4>
<p>Let's start with a simple example using AIoT:</p>
<pre><code>sample_query = "What is the capital of France?"
final_response_aiot = iot.aiot(sample_query)
print(final_response_aiot)
</code></pre>
<p>In this example, we ask a straightforward question about France's capital. The AI will generate an initial response and refine it through iterations until it reaches a satisfactory answer.</p>
<h4>Intermediate Example: Refining Responses</h4>
<p>Now let's look at an intermediate example using GIoT:</p>
<pre><code>sample_query = "Explain photosynthesis."
final_response_giot = iot.giot(sample_query, fixed_iterations=3)
print(final_response_giot)
</code></pre>
<p>Here, we are asking for an explanation of photosynthesis over three iterations, allowing us to obtain a more detailed understanding each time.</p>
<h4>Advanced Example: Complex Query Iteration</h4>
<p>For our advanced example, let's tackle a more complex query:</p>
<pre><code>sample_query = "Describe the impact of climate change on marine biodiversity."
final_response_aiot = iot.aiot(sample_query)
print(final_response_aiot)
</code></pre>
<p>This query might require multiple iterations for deeper insights into various aspects related to climate change and marine life.</p>
<h3>5. Interactive Elements</h3>
<h4>Quick Quiz: Test Your Knowledge üß†‚ú®</h4>
<p><strong>Question:</strong> What are the two main components of the IoT framework? ü§î</p>
<p>‚Ä¢ A) AIoT and GIoT üåêüîÑ</p>
<p>‚Ä¢ B) Machine Learning and Deep Learning üìäüß†</p>
<p>‚Ä¢ C) Data Science and Data Engineering üìàüîß</p>
<p><em>Pause and reflect before checking your answer!</em></p>
<h3>6. Pro Tips</h3>
<p>‚Ä¢ <strong>Craft Effective Prompts:</strong> The quality of your prompts significantly influences response quality. Be clear and specific.</p>
<p>‚Ä¢ <strong>Iterate Wisely:</strong> Not all queries require multiple iterations; assess when it's necessary based on complexity.</p>
<h3>7. Common Misconceptions</h3>
<p>Many users believe that simply sending queries to AI will yield perfect results without needing refinement‚Äîthis is a misconception! Iterative frameworks like IoT are essential for enhancing response accuracy and relevance.</p>
<h3>8. Sequence Diagram: Understanding IoT Process</h3>
<p>To visualize how the IoT framework operates, here's a Mermaid sequence diagram illustrating the interaction between different components during response generation:</p>
<pre><code>sequenceDiagram
    participant User as User
    participant AI as OpenAI Model
    participant IDA as Inner Dialogue Agent
    participant LLM as LLM Agent

    User-&gt;&gt;LLM: Send initial query
    LLM-&gt;&gt;AI: Generate initial response
    AI--&gt;&gt;LLM: Return response
    LLM--&gt;&gt;User: Show initial response

    User-&gt;&gt;IDA: Request refinement with previous response
    IDA-&gt;&gt;AI: Generate new prompt based on previous response
    AI--&gt;&gt;IDA: Return refined prompt

    IDA-&gt;&gt;LLM: Send refined prompt
    LLM-&gt;&gt;AI: Generate refined response
    AI--&gt;&gt;LLM: Return refined response
    LLM--&gt;&gt;User: Show refined response

    Note over User, LLM: Repeat process until stopping criterion met
</code></pre>
<h3>9. Conclusion</h3>
<h4>Call-to-Action: Apply What You've Learned!</h4>
<p>To put your new knowledge into practice within 24 hours:</p>
<p>1Ô∏è‚É£  Choose a topic you're passionate about.</p>
<p>2Ô∏è‚É£  Formulate a query related to that topic.</p>
<p>3Ô∏è‚É£  Implement either AIoT or GIoT using the provided code structure.</p>
<p>4Ô∏è‚É£  Share your refined response with peers or colleagues!</p>
<p>By taking these steps, you'll not only reinforce what you've learned but also begin applying it in real-world scenarios‚Äîempowering you as a practitioner in no time!</p>

</body>
</html>
